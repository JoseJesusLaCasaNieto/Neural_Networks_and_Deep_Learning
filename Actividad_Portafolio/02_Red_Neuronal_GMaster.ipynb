{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 07MIAR_Proyecto_Programación - Plant Seedlings Classification"
      ],
      "metadata": {
        "id": "gxSaFqvbPCFi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Librerías"
      ],
      "metadata": {
        "id": "-7g3-Pgq1Piu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.color import rgb2hsv\n",
        "import json\n",
        "import pandas as pd\n",
        "from tensorflow.keras import Sequential\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, MaxPooling2D, BatchNormalization, Dropout, Conv2D, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.preprocessing import image\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "N6L9WsLQ1UAB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Lectura de los datos"
      ],
      "metadata": {
        "id": "YX2YVq8MPRf2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1. Conexión remota con Google Drive"
      ],
      "metadata": {
        "id": "kwbrRcX71xqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Conexión remota con Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "fVe8i5erPPCW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7733de09-5f77-4499-c79b-91ea80553be5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2. Establecer ruta directa al directorio y lectura de datos"
      ],
      "metadata": {
        "id": "fkmdN7eR11yn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Establecimiento de una ruta absoluta al directorio de Google Drive\n",
        "BASE_FOLDER = \"/content/drive/MyDrive/BASE_FOLDER/\"\n",
        "DATASET = BASE_FOLDER + \"my_dataset/ohe_data_train_resize_224.h5\""
      ],
      "metadata": {
        "id": "GCNFEooMRTLV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lectura del dataset\n",
        "df = pd.read_hdf(DATASET,key='data')"
      ],
      "metadata": {
        "id": "20GY33yxFHoi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Red Neuronal Convolucional GMaster"
      ],
      "metadata": {
        "id": "v7Edd1iHUX6g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1. Función para crear la red neuronal"
      ],
      "metadata": {
        "id": "WuWcIQLO2EY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para crear la red neuronal\n",
        "def make_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
        "                     activation='relu', strides=1, padding='same',\n",
        "                     input_shape=(224, 224, 3)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
        "                     activation='relu', strides=1, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(filters=64, kernel_size=(3, 3),\n",
        "                     activation='relu', strides=1, padding='same'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(filters=128, kernel_size=(3, 3),\n",
        "                     activation='relu', strides=1, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "LqQkxFZoUdd7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2. Análisis de la red neuronal"
      ],
      "metadata": {
        "id": "bfWbXFZn2KBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el modelo en una variable\n",
        "model = make_model()\n",
        "\n",
        "# Visualización de las capas de la red neuronal\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "g4r3FCd-2P1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Prepocesado de datos."
      ],
      "metadata": {
        "id": "gYqPZHt93CAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 'X' contiene las imágenes e 'y' contiene las etiquetas de las imágenes\n",
        "X = np.array(df['imagen'].tolist())   # Convertir X a un arreglo NumPy\n",
        "y = df.iloc[:, 1:]  # Selecciona todas las columnas excepto la primera (X)\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba en un 20% del total y con una semilla de aleatoriedad constante\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Análisis de las dimensiones de los datos y etiquetas\n",
        "print(\"Dimensiones de 'X_train':\", X_train.shape)\n",
        "print(\"Dimensiones de 'X_test':\", X_test.shape)\n",
        "print(\"Dimensiones de 'y_train':\", y_train.shape)\n",
        "print(\"Dimensiones de 'y_test':\", y_test.shape)"
      ],
      "metadata": {
        "id": "Dgp8zkFHVa7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Hiperparámetros y entrenamiento de la red neuronal"
      ],
      "metadata": {
        "id": "4I5Vgoda4-Eu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1. Hiperparámetros"
      ],
      "metadata": {
        "id": "kekzHma8_xyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hiperparámetros\n",
        "reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda x: 0.01 * 0.9**x)   # Reduce el learning rate según avanza el entrenamiento por cada época\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)   # Detiene el entrenamiento cuando se haya repetido el val_accuracy un número determinado de veces durante el entrenamiento (evita el overfitting)\n",
        "epochs = 30   # Número de épocas\n",
        "validation_split = 0.2    # Partición de los datos para validación"
      ],
      "metadata": {
        "id": "8ZX9fo74_20L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2. Entrenamiento del modelo"
      ],
      "metadata": {
        "id": "NcdaQSbHBgdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(\"[INFO] Entrenando Red Neuronal...\")\n",
        "history = model.fit(X_train, y_train, epochs=epochs, callbacks=[reduce_lr], validation_split=validation_split)"
      ],
      "metadata": {
        "id": "DnhRvZCd263y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Evaluación del modelo"
      ],
      "metadata": {
        "id": "gK-e-KEdEKIb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1. Análisis de 'test loss' y 'test accuracy'"
      ],
      "metadata": {
        "id": "1hmGdN2fEsFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 'Test loss' y 'test accuracy'\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(\"Test loss:\", test_loss)\n",
        "print(\"Test accuracy:\", test_acc)"
      ],
      "metadata": {
        "id": "A8_GptfpEYRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2. Representación gráfica"
      ],
      "metadata": {
        "id": "VpEXnF7lEzNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_learning_curves(history):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    # Plot de pérdida\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlim(0, len(history.history['loss']))  # Establece límites para el eje x\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot de precisión\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.ylim(0, 1)  # Establece límites para el eje y\n",
        "    plt.xlim(0, len(history.history['accuracy']))  # Establece límites para el eje x\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_learning_curves(history)"
      ],
      "metadata": {
        "id": "2xTqHQc-mcU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3. Matriz de confusión"
      ],
      "metadata": {
        "id": "w2gFzCkAFBaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener predicciones del conjunto de prueba\n",
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "# Convertir las predicciones de las clases en etiquetas\n",
        "y_pred_classes = np.argmax(Y_pred, axis=1)\n",
        "y_true = np.argmax(y_test.values, axis=1)\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "confusion_mtx = confusion_matrix(y_true, y_pred_classes)\n",
        "clases = [\n",
        "    \"Black-grass\",\n",
        "    \"Charlock\",\n",
        "    \"Cleavers\",\n",
        "    \"Common Chickweed\",\n",
        "    \"Common wheat\",\n",
        "    \"Fat Hen\",\n",
        "    \"Loose Silky-bent\",\n",
        "    \"Maize\",\n",
        "    \"Scentless Mayweed\",\n",
        "    \"Shepherds Purse\",\n",
        "    \"Small-flowered Cranesbill\",\n",
        "    \"Sugar beet\"\n",
        "]\n",
        "# Visualizar la matriz de confusión\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(confusion_mtx, annot=True, fmt='d', cmap='Blues', xticklabels=clases, yticklabels=clases)\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Etiqueta verdadera')\n",
        "plt.title('Matriz de confusión')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qS-vOAikvrNm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}